{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c44b8da-5cb6-463f-b275-0be5085026fa",
   "metadata": {},
   "source": [
    "2D Omnipose segmentation\n",
    "============================\n",
    "\n",
    "Before running this notebook, install the latest version of Omnipose from GitHub. This automatically installs our Cellpose fork. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281bf04d-fcc3-4f83-acc0-2476c9ebe310",
   "metadata": {
    "tags": [
     "remove-output",
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# make local editable packages automatically reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df70baa5-f9e8-47cc-a419-ff637a925f33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:52:13,396 [INFO] TORCH GPU version not installed/working.\n",
      ">>> GPU activated? False\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "from cellpose_omni import models, core\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you \n",
    "# are only processing a few images.\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? {}'.format(use_GPU))\n",
    "\n",
    "# for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1452d605-54d0-417e-a720-33436e319231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from cellpose_omni import io\n",
    "import omnipose\n",
    "\n",
    "# Set the path to the desired folder\n",
    "basedir = 'PilG_dilute_PC_contr5'\n",
    "\n",
    "# Get the list of image files from the folder\n",
    "files = io.get_image_files(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd67a3b-435d-45a3-b966-cfee2f29ba80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of images: 241\n"
     ]
    }
   ],
   "source": [
    "from cellpose_omni import io, transforms\n",
    "from omnipose.utils import normalize99\n",
    "imgs = [io.imread(f) for f in files]\n",
    "\n",
    "#print some info about the images.\n",
    "#for i in imgs:\n",
    "#    print('Original image shape:',i.shape)\n",
    "#    print('data type:',i.dtype)\n",
    "#    print('data range: min {}, max {}\\n'.format(i.min(),i.max()))\n",
    "nimg = len(imgs)\n",
    "print('\\nnumber of images:',nimg)\n",
    "\n",
    "#fig = plt.figure(figsize=[40]*2,frameon=False) # initialize figure\n",
    "#print('\\n')\n",
    "#for k in range(len(imgs)):\n",
    "#    img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "#    if len(img.shape)>2:\n",
    "#        imgs[k] = img[:,:,1] # could pick out a specific channel\n",
    "#        imgs[k] = np.mean(img,axis=-1) # or just turn into grayscale \n",
    "        \n",
    "#    imgs[k] = normalize99(imgs[k])\n",
    "#    imgs[k] = np.pad(imgs[k],10,'edge')\n",
    "#    print('new shape: ', imgs[k].shape)\n",
    "#    plt.subplot(1,len(files),k+1)\n",
    "#    plt.imshow(imgs[k],cmap='gray')\n",
    "#    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635d57e-72e7-415b-aea5-73990f9450e2",
   "metadata": {},
   "source": [
    "## Initialize model\n",
    "Here we use one of the built-in model names. We will choose the `bact_phase_omni` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f645d6-c2cc-45bb-80da-22efa8cb4901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-13 20:53:58,281 [INFO] >>bact_phase_omni<< model set to be used\n",
      "2023-11-13 20:53:58,282 [INFO] >>>> using CPU\n"
     ]
    }
   ],
   "source": [
    "from cellpose_omni import models\n",
    "from cellpose_omni.models import MODEL_NAMES\n",
    "\n",
    "model_name = 'bact_phase_omni'\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469856ad-65c8-4ba7-b371-e2661516c413",
   "metadata": {},
   "source": [
    "## Run segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382c604-9a23-4f74-b090-a54c64d252bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "chans = [0,0] #this means segment based on first channel, no second channel \n",
    "\n",
    "#n = [1] # make a list of integers to select which images you want to segment\n",
    "n = range(nimg) # or just segment them all \n",
    "\n",
    "# define parameters\n",
    "params = {'channels':chans, # always define this with the model\n",
    "          'rescale': None, # upscale or downscale your images, None = no rescaling \n",
    "          'mask_threshold': 2.55, # erode or dilate masks with higher or lower values \n",
    "          'flow_threshold': 0, # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "          'transparency': True, # transparency in flow output\n",
    "          'omni': True, # we can turn off Omnipose mask reconstruction, not advised \n",
    "          'cluster': True, # use DBSCAN clustering\n",
    "          'resample': True, # whether or not to run dynamics on rescaled grid or original grid \n",
    "          # 'verbose': False, # turn on if you want to see more output \n",
    "          'tile': False, # average the outputs from flipped (augmented) images; slower, usually not needed \n",
    "          'niter': None, # None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation \n",
    "          'augment': False, # Can optionally rotate the image and average outputs, usually not needed \n",
    "          'affinity_seg': False, # new feature, stay tuned...\n",
    "         }\n",
    "\n",
    "\n",
    "total_segmentation_time = 0\n",
    "\n",
    "# Loop through each image, segment and save\n",
    "for i in tqdm(n, 'Segmentation progress:'):\n",
    "    tic = time.time()  # start time for this iteration\n",
    "    \n",
    "    # Perform segmentation on the i-th image\n",
    "    mask, flow, style = model.eval(imgs[i], **params)\n",
    "    \n",
    "    # Calculate segmentation time for this image\n",
    "    seg_time = time.time() - tic\n",
    "    total_segmentation_time += seg_time  # add to total time\n",
    "    \n",
    "    print(f'Segmentation time for image {i}: {seg_time}s')\n",
    "    \n",
    "    # Define the file path for saving the results\n",
    "    file_path = files[i]  # Assuming 'files' is your list of file paths for the images\n",
    "    \n",
    "    # Save the masks for the i-th image\n",
    "    io.save_masks([imgs[i]], [mask], [flow], [file_path], \n",
    "                  png=False,\n",
    "                  tif=True,\n",
    "                  suffix='',  # Add suffix if needed\n",
    "                  save_flows=False,\n",
    "                  save_outlines=False,\n",
    "                  dir_above=0,\n",
    "                  in_folders=True,\n",
    "                  save_txt=False,\n",
    "                  save_ncolor=False)\n",
    "    \n",
    "print(f'Total segmentation time for all images: {total_segmentation_time}s')\n",
    "\n",
    "average_time_per_image = total_segmentation_time / nimg\n",
    "expected_total_time = average_time_per_image * nimg\n",
    "print(f'Expected total time for segmenting all images: {expected_total_time}s')"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
